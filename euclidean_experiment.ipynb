{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LASA DataSet from /home/stanislav/anaconda3/envs/ml_env/lib/python3.12/site-packages/pyLasaDataset/resources/LASAHandwritingDataset/DataSet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "from models.state_mlp import StateMLP\n",
    "from data.lasa_data import StatePyLASADataset\n",
    "from utils.train_utils import CondOT_flow, CondOT_ut, validate\n",
    "from utils.plotting import plot_flow, plot_error_for_each_point\n",
    "from utils.schemes import Euler, RK4\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0001,\n",
       " 'epochs': 5401,\n",
       " 'batch_size': 1200,\n",
       " 'inf_every': 900,\n",
       " 'print_every': 300,\n",
       " 'dim': 2,\n",
       " 'hidden_dim': 64,\n",
       " 'horizon_size': 8,\n",
       " 'inference_horizon': 4,\n",
       " 'scale_factor': 2.0,\n",
       " 'downsample': 5,\n",
       " 'ema_warmup': 20,\n",
       " 'ema_update': 5,\n",
       " 'ema_decay': 0.999,\n",
       " 'inf_runs_num': 3,\n",
       " 'save_epoch': 6000,\n",
       " 'device': 'cpu'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_parameters =  yaml.safe_load(Path(\"./configs/base.yaml\").read_text())\n",
    "run_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_data = StatePyLASADataset(\"Sine\", horizon_size=run_parameters['horizon_size'],\n",
    "                                       scaling_factor=run_parameters['scale_factor'],\n",
    "                                       downsample = run_parameters['downsample'])\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(sine_data, range(6000//run_parameters['downsample']))\n",
    "\n",
    "test_dataset = torch.utils.data.Subset(sine_data, range(6000//run_parameters['downsample'], \n",
    "                                                        7000//run_parameters['downsample']))\n",
    "\n",
    "train_sin = DataLoader(train_dataset,\n",
    "                       batch_size=run_parameters['batch_size'],\n",
    "                       shuffle=True)\n",
    "\n",
    "val_sin = DataLoader(test_dataset,\n",
    "                    batch_size=run_parameters['batch_size'],\n",
    "                    shuffle=True)\n",
    "\n",
    "test_sin = DataLoader(test_dataset,\n",
    "                    batch_size=1,\n",
    "                    shuffle=False)\n",
    "\n",
    "inf_obs, _ = next(iter(test_sin))\n",
    "inf_obs = inf_obs[:, :2]\n",
    "\n",
    "gt_test = DataLoader(test_dataset,\n",
    "                    batch_size=1000//run_parameters['downsample'],\n",
    "                    shuffle=False)\n",
    "\n",
    "gt_obs, gt_horizon = next(iter(gt_test))\n",
    "gt_obs = gt_obs[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 5]) torch.Size([1200, 8, 2])\n",
      "Learnable param number: 40864\n"
     ]
    }
   ],
   "source": [
    "vf = StateMLP(\n",
    "    action_dim=run_parameters['dim'],\n",
    "    hidden_dim=run_parameters['hidden_dim'],\n",
    "    horizon_size=run_parameters['horizon_size'],\n",
    ")\n",
    "\n",
    "ema_vf = ExponentialMovingAverage(\n",
    "    vf.parameters(),\n",
    "    decay = run_parameters['ema_decay'],\n",
    ")\n",
    "\n",
    "obs, a = next(iter(train_sin))\n",
    "print(obs.shape, a.shape)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, vf.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Learnable param number:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| iter      0 |  0.08 ms/step | loss    2.267 \n",
      "| iter      0 | validation loss:    2.666 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:00<00:02, 14.91it/s]"
     ]
    }
   ],
   "source": [
    "device = run_parameters['device']\n",
    "vf.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(vf.parameters(), lr=run_parameters['lr'])\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(run_parameters['epochs']):\n",
    "  for batch in train_sin:\n",
    "    optim.zero_grad()\n",
    "\n",
    "    obs, a1 = batch\n",
    "    obs, a1 = obs.to(device), a1.to(device)\n",
    "\n",
    "    a0 = torch.randn(a1.shape[0], 1, a1.shape[2])\n",
    "    a0 = a0.repeat(1, a1.shape[1], 1).to(device)\n",
    "\n",
    "    #a0 = torch.randn_like(a1)\n",
    "    t = torch.rand(a1.shape[0]).to(device)\n",
    "\n",
    "    a_t = CondOT_flow(a0, a1, t)\n",
    "    da_t = CondOT_ut(a0, a1, t)\n",
    "\n",
    "    loss = torch.pow(vf(obs=obs, a=a_t, t=t) - da_t, 2).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i > run_parameters['ema_warmup'] and i % run_parameters['ema_update'] == 0: \n",
    "      ema_vf.update()\n",
    "\n",
    "  if i % run_parameters['print_every'] == 0:\n",
    "      elapsed = time.time() - start_time\n",
    "      print('| iter {:6d} | {:5.2f} ms/step | loss {:8.3f} '\n",
    "            .format(i, elapsed*1000/run_parameters['print_every'], loss.item()))\n",
    "      start_time = time.time()\n",
    "      with torch.no_grad():\n",
    "        # loss_val = validate(val_sin)\n",
    "        # print('| iter {:6d} | validation loss: {:8.3f} '.format(i, loss_val))\n",
    "        ema_vf.store()\n",
    "        ema_vf.copy_to()\n",
    "        loss_val = validate(vf, val_sin)\n",
    "        ema_vf.restore()  # Restore original weights\n",
    "        print('| iter {:6d} | validation loss: {:8.3f} '.format(i, loss_val))\n",
    "  if i > 0 and i % run_parameters['save_epoch'] == 0:\n",
    "    print(\"Saving checkpoint for \" + str(i) + \"th epoch\")\n",
    "    torch.save(vf.state_dict(), \"./vf_lipman\" + str(run_parameters['scale_factor']) + \"_\" + str(i) + \".pth\")\n",
    "\n",
    "  if i % run_parameters['inf_every'] == 0:\n",
    "    with torch.no_grad():\n",
    "      ema_vf.store()\n",
    "      ema_vf.copy_to()\n",
    "      results = []\n",
    "      samples = []\n",
    "      for _ in range(run_parameters['inf_runs_num']):\n",
    "        res, samp = infer_model(model=vf,\n",
    "                                start=inf_obs,\n",
    "                                scheme=RK4,\n",
    "                                inference_horizon=run_parameters['inference_horizon'],\n",
    "                                sample_points=1000//run_parameters['downsample'])\n",
    "        results.append(res)\n",
    "        samples.append(samp)\n",
    "      error = evaluate_model(model=vf, \n",
    "                             gt_obs=gt_obs,\n",
    "                             horizon_obs=gt_horizon,\n",
    "                             scheme=RK4, \n",
    "                             num_steps=100)\n",
    "      plot_flow(results, samples, gt_obs)\n",
    "      plot_error_for_each_point(gt_obs, error)\n",
    "      ema_vf.restore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
