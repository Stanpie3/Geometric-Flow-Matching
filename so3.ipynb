{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0eb1084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LASA DataSet from /home/stanislav/anaconda3/envs/ml_env/lib/python3.12/site-packages/pyLasaDataset/resources/LASAHandwritingDataset/DataSet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "from models.state_mlp import StateMLP\n",
    "from data.lasa_data import StatePyLASADataset, wrap\n",
    "from utils.plotting import *\n",
    "from utils.manifold_utils import *\n",
    "from utils.pytorch3d import *\n",
    "from utils.so3 import *\n",
    "\n",
    "from flow_matching.utils.manifolds import Manifold, Sphere, Euclidean\n",
    "from flow_matching.path import GeodesicProbPath\n",
    "from flow_matching.path.scheduler import CondOTScheduler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from soft_dtw import SoftDTW\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd074bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x735394f73bd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(3420934659826)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4f6b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'lr': 0.0001,\n",
       "  'epochs': 100001,\n",
       "  'batch_size': 100,\n",
       "  'inf_every': 4000,\n",
       "  'print_every': 4000,\n",
       "  'device': 'cpu',\n",
       "  'inf_runs_num': 3,\n",
       "  'inf_run_step': 0.05},\n",
       " 'model': {'hidden_dim': 128, 'num_layers': 6, 'embed_dim': 24},\n",
       " 'data': {'dim': 4,\n",
       "  'manifold': 'Sphere',\n",
       "  'datasets': ['Sine'],\n",
       "  'horizon_size': 20,\n",
       "  'inference_horizon': 10,\n",
       "  'scale_factor': 1.5,\n",
       "  'downsample': 5,\n",
       "  'sample_points': 300,\n",
       "  'mean': 0.0,\n",
       "  'std': 0.5},\n",
       " 'ema': {'warmup': 2000, 'update': 5, 'decay': 0.999},\n",
       " 'scheduler': {'step': 10000, 'gamma': 0.5}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_parameters =  yaml.safe_load(Path(\"./configs/so3.yaml\").read_text())\n",
    "run_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5bf3c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6] [0]\n"
     ]
    }
   ],
   "source": [
    "manifold_types = {'None' : None, 'Euclidean': Euclidean(), 'Sphere':Sphere()}\n",
    "val_sets=[0]\n",
    "train_sets = list(range(1,7))\n",
    "print(train_sets, val_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69c948f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "1\n",
      "6\n",
      "torch.Size([1, 200, 9])\n"
     ]
    }
   ],
   "source": [
    "manifold = manifold_types[run_parameters['data']['manifold']]\n",
    "LASA_datasets = run_parameters['data']['datasets']\n",
    "\n",
    "dataset = StatePyLASADataset(LASA_datasets,\n",
    "                               train=train_sets,\n",
    "                               horizon_size=run_parameters['data']['horizon_size'],\n",
    "                               scaling_factor=run_parameters['data']['scale_factor'],\n",
    "                               downsample = run_parameters['data']['downsample'],\n",
    "                               manifold=manifold,\n",
    "                               dim_to=run_parameters['data']['dim'],\n",
    "                               rotate=True)\n",
    "\n",
    "print(dataset.__len__())\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_sets)\n",
    "\n",
    "test_dataset = torch.utils.data.Subset(dataset, val_sets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                       batch_size=run_parameters['train']['batch_size'],\n",
    "                       shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(test_dataset,\n",
    "                    batch_size=run_parameters['train']['batch_size'],\n",
    "                    shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                    batch_size=1,\n",
    "                    shuffle=False)\n",
    "\n",
    "inf_obs, _, label = next(iter(test_dataloader))\n",
    "inf_obs = inf_obs[:, :2]\n",
    "\n",
    "gt_test = DataLoader(test_dataset,\n",
    "                    batch_size=4,\n",
    "                    shuffle=False)\n",
    "\n",
    "print(test_dataset.__len__())\n",
    "print(train_dataset.__len__())\n",
    "\n",
    "gt_obs, gt_horizon, label = next(iter(gt_test))\n",
    "print(gt_obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57210efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_normal_SO3(batch_size=1200, horizon=10, mean=None, std=torch.tensor(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a639f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9172,  0.1681,  0.3611],\n",
      "        [-0.2092,  0.9748,  0.0776],\n",
      "        [-0.3390, -0.1467,  0.9293]])\n"
     ]
    }
   ],
   "source": [
    "print(samples[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480a21b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9172,  0.1681],\n",
       "        [-0.2092,  0.9748],\n",
       "        [-0.3390, -0.1467]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_2_R6(samples[0][0]).view(2,3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b5ef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9172,  0.1681,  0.3611],\n",
       "        [-0.2092,  0.9748,  0.0776],\n",
       "        [-0.3390, -0.1467,  0.9293]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhou_6d_to_so3(BM_2_R6(samples[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eec9eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9172,  0.1681,  0.3611],\n",
      "        [-0.2092,  0.9748,  0.0776],\n",
      "        [-0.3390, -0.1467,  0.9293]])\n"
     ]
    }
   ],
   "source": [
    "print(procrustes_to_so3(BM_2_R9(samples)[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63435757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test_zhou = BM_2_R6(samples)\n",
    "test_proc = BM_2_R9(samples)\n",
    "res_zhou = zhou_6d_to_so3(test_zhou)\n",
    "print(torch.allclose(samples, res_zhou, atol=1e-6))\n",
    "rec_proc = procrustes_to_so3(test_proc)\n",
    "print(torch.allclose(samples, rec_proc, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9203ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_obs_mat = quaternion_to_matrix(gt_obs[:,:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2df74cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(zhou_6d_to_so3(BM_2_R6(gt_obs_mat)), gt_obs_mat, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c500c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_config_to_yaml(config: Dict[str, Any], filepath: str) -> None:\n",
    "    try:\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(config, f, default_flow_style=False)  \n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Failed to save config to {filepath}\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a0eff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learnable params number: 144776\n"
     ]
    }
   ],
   "source": [
    "vf = StateMLP(\n",
    "    action_dim=6,\n",
    "    hidden_dim=run_parameters['model']['hidden_dim'],\n",
    "    horizon_size=run_parameters['data']['horizon_size'],\n",
    "    num_layers=run_parameters['model']['num_layers'],\n",
    "    label_embedding_dim=run_parameters['model']['embed_dim'],\n",
    "    num_classes=len(run_parameters['data']['datasets'])\n",
    ")\n",
    "ema_vf = ExponentialMovingAverage(\n",
    "    vf.parameters(),\n",
    "    decay = run_parameters['ema']['decay'],\n",
    ")\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, vf.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Learnable params number:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c16586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def run_train(vf, train_dataloader, \n",
    "              val_dataloader, \n",
    "              run_parameters, \n",
    "              manifold, \n",
    "              ema_vf, dataset, \n",
    "              gt_obs, \n",
    "              run_name, run_path=\"./runs\"):\n",
    "    save_path = os.path.join(run_path, run_name)\n",
    "    os.makedirs(save_path, exist_ok=False)\n",
    "    save_config_to_yaml(run_parameters, os.path.join(save_path, 'config.yaml'))\n",
    "    \n",
    "    device = run_parameters['train']['device']\n",
    "    vf.to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(vf.parameters(), lr=run_parameters['train']['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, \n",
    "                                               step_size=run_parameters['scheduler']['step'], \n",
    "                                               gamma=run_parameters['scheduler']['gamma'])\n",
    "\n",
    "    path = GeodesicProbPath(scheduler=CondOTScheduler(), manifold=manifold)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    lrs = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i in range(run_parameters['train']['epochs']):\n",
    "        for batch in train_dataloader:\n",
    "            optim.zero_grad()\n",
    "\n",
    "            train_loss = step(vf=vf, \n",
    "                              batch=batch, \n",
    "                              run_parameters=run_parameters, \n",
    "                              manifold=manifold, \n",
    "                              path=path, \n",
    "                              device=device,\n",
    "                              base='R6')\n",
    "            \n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            if i > run_parameters['ema']['warmup'] and i % run_parameters['ema']['update'] == 0: \n",
    "                ema_vf.update()\n",
    "\n",
    "            if i % run_parameters['train']['print_every'] == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print('| iter {:6d} | {:5.2f} sec | train loss {:8.3f} '\n",
    "                      .format(i, elapsed, train_loss.item()))\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.plot(train_losses, label='Training Loss')\n",
    "                plt.plot(val_losses, label='Validation Loss')\n",
    "                plt.xlabel('Iterations (x print_every)')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(save_path,'loss_plot.png'))\n",
    "                plt.close()\n",
    "\n",
    "                plt.figure()\n",
    "                plt.plot(lrs, label='Learning rate')\n",
    "                plt.xlabel('Iterations (x print_every)')\n",
    "                plt.ylabel('lr')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(save_path,'lr_plot.png'))\n",
    "                plt.close()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    ema_vf.store()\n",
    "                    ema_vf.copy_to()\n",
    "                    val_batch = next(iter(val_dataloader))\n",
    "                    loss_val = step(vf=vf, \n",
    "                                    batch=val_batch, \n",
    "                                    run_parameters=run_parameters, \n",
    "                                    manifold=manifold, \n",
    "                                    path=path, \n",
    "                                    device=device,\n",
    "                                    base='R6')\n",
    "                    train_losses.append(train_loss.item())\n",
    "                    val_losses.append(loss_val.item())\n",
    "                    if loss_val.item() < best_val_loss:\n",
    "                        best_val_loss = loss_val.item()\n",
    "                        torch.save(vf.state_dict(), os.path.join(save_path, 'best_model.pth'))\n",
    "                    print('| iter {:6d} | validation loss: {:8.3f} '.format(i, loss_val.item()))\n",
    "\n",
    "                    # infered = run_inference(manifold=manifold,\n",
    "                    #             model=vf,\n",
    "                    #             run_parameters=run_parameters,\n",
    "                    #             class_labels=dataset.get_label_maping(),\n",
    "                    #             gt_obs=gt_obs)\n",
    "                    # plt.plot(infered['Sine']['results'][0])\n",
    "                    # plt.show()\n",
    "                    # for label_name in infered.keys():\n",
    "                    #     plot_flow_on_sphere(infered[label_name]['results'], \n",
    "                    #                         infered[label_name]['samples'], \n",
    "                    #                         gt_obs[dataset.get_label_maping()[label_name]],\n",
    "                    #                         label=label_name)\n",
    "                    ema_vf.restore()\n",
    "                start_time = time.time()\n",
    "        lrs.append(scheduler.get_last_lr()[0])\n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "\n",
    "    vf.load_state_dict(torch.load(os.path.join(save_path,'best_model.pth'), weights_only=True))\n",
    "    # with torch.no_grad():\n",
    "    #     infered = run_inference(manifold=manifold,\n",
    "    #                             model=vf,\n",
    "    #                             run_parameters=run_parameters,\n",
    "    #                             class_labels=dataset.get_label_maping(),\n",
    "    #                             gt_obs=gt_obs)\n",
    "    #     for label_name in infered.keys():\n",
    "    #         plot_flow_on_sphere(infered[label_name]['results'], \n",
    "    #                             infered[label_name]['samples'], \n",
    "    #                             gt_obs[dataset.get_label_maping()[label_name]],\n",
    "    #                             label=label_name)\n",
    "    #         plt.savefig(os.path.join(save_path, f'best_model_flow_{label_name}.png'))\n",
    "    #         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| iter      0 |  0.13 sec | train loss    0.804 \n",
      "| iter      0 | validation loss:    0.813 \n"
     ]
    }
   ],
   "source": [
    "run_train(vf=vf, \n",
    "            train_dataloader=train_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "            run_parameters=run_parameters, \n",
    "            manifold=Euclidean(), \n",
    "            ema_vf=ema_vf, dataset=dataset, \n",
    "            gt_obs=gt_obs, \n",
    "            run_name=\"sine_shape_R6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508efdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
