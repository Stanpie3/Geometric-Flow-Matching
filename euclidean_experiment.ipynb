{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LASA DataSet from /home/stanislav/anaconda3/envs/ml_env/lib/python3.12/site-packages/pyLasaDataset/resources/LASAHandwritingDataset/DataSet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "from models.state_mlp import StateMLP\n",
    "from data.lasa_data import StatePyLASADataset\n",
    "from utils.train_utils import CondOT_flow, CondOT_ut, validate\n",
    "from utils.plotting import plot_flow, plot_error_for_each_point\n",
    "from utils.schemes import Euler, RK4\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0001,\n",
       " 'epochs': 15001,\n",
       " 'batch_size': 1200,\n",
       " 'inf_every': 1000,\n",
       " 'print_every': 500,\n",
       " 'dim': 2,\n",
       " 'hidden_dim': 64,\n",
       " 'horizon_size': 8,\n",
       " 'inference_horizon': 4,\n",
       " 'scale_factor': 2.0,\n",
       " 'downsample': 5,\n",
       " 'ema_warmup': 250,\n",
       " 'ema_update': 5,\n",
       " 'ema_decay': 0.999,\n",
       " 'inf_runs_num': 3,\n",
       " 'save_epoch': 6000,\n",
       " 'device': 'cpu'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_parameters =  yaml.safe_load(Path(\"./configs/base.yaml\").read_text())\n",
    "run_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_data = StatePyLASADataset(\"Sine\", horizon_size=run_parameters['horizon_size'],\n",
    "                                       scaling_factor=run_parameters['scale_factor'],\n",
    "                                       downsample = run_parameters['downsample'])\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(sine_data, range(6000//run_parameters['downsample']))\n",
    "\n",
    "test_dataset = torch.utils.data.Subset(sine_data, range(6000//run_parameters['downsample'], \n",
    "                                                        7000//run_parameters['downsample']))\n",
    "\n",
    "train_sin = DataLoader(train_dataset,\n",
    "                       batch_size=run_parameters['batch_size'],\n",
    "                       shuffle=True)\n",
    "\n",
    "val_sin = DataLoader(test_dataset,\n",
    "                    batch_size=run_parameters['batch_size'],\n",
    "                    shuffle=True)\n",
    "\n",
    "test_sin = DataLoader(test_dataset,\n",
    "                    batch_size=1,\n",
    "                    shuffle=False)\n",
    "\n",
    "inf_obs, _ = next(iter(test_sin))\n",
    "inf_obs = inf_obs[:, :2]\n",
    "\n",
    "gt_test = DataLoader(test_dataset,\n",
    "                    batch_size=1000//run_parameters['downsample'],\n",
    "                    shuffle=False)\n",
    "\n",
    "gt_obs, gt_horizon = next(iter(gt_test))\n",
    "gt_obs = gt_obs[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 5]) torch.Size([1200, 8, 2])\n",
      "Learnable param number: 40864\n"
     ]
    }
   ],
   "source": [
    "vf = StateMLP(\n",
    "    action_dim=run_parameters['dim'],\n",
    "    hidden_dim=run_parameters['hidden_dim'],\n",
    "    horizon_size=run_parameters['horizon_size'],\n",
    ")\n",
    "\n",
    "ema_vf = ExponentialMovingAverage(\n",
    "    vf.parameters(),\n",
    "    decay = run_parameters['ema_decay'],\n",
    ")\n",
    "\n",
    "obs, a = next(iter(train_sin))\n",
    "print(obs.shape, a.shape)\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, vf.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Learnable param number:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| iter      0 |  0.06 ms/step | loss    2.265 \n",
      "| iter      0 | validation loss:    2.465 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [00:03<00:00, 13.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(run_parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf_runs_num\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 52\u001b[0m   res, samp \u001b[38;5;241m=\u001b[39m infer_model(model\u001b[38;5;241m=\u001b[39mvf,\n\u001b[1;32m     53\u001b[0m                           start\u001b[38;5;241m=\u001b[39minf_obs,\n\u001b[1;32m     54\u001b[0m                           scheme\u001b[38;5;241m=\u001b[39mRK4,\n\u001b[1;32m     55\u001b[0m                           inference_horizon\u001b[38;5;241m=\u001b[39mrun_parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference_horizon\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     56\u001b[0m                           sample_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mrun_parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownsample\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     57\u001b[0m   results\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[1;32m     58\u001b[0m   samples\u001b[38;5;241m.\u001b[39mappend(samp)\n",
      "File \u001b[0;32m~/projects/python/thesis/Geometric-Flow-Matching/utils/utils.py:51\u001b[0m, in \u001b[0;36minfer_model\u001b[0;34m(model, start, scheme, num_steps, sample_points, inference_horizon, model_horizon, action_dim)\u001b[0m\n\u001b[1;32m     48\u001b[0m a0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, action_dim)\n\u001b[1;32m     49\u001b[0m a0 \u001b[38;5;241m=\u001b[39m a0\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, model_horizon, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m at \u001b[38;5;241m=\u001b[39m scheme(wrapped_vf, a0, num_steps\u001b[38;5;241m=\u001b[39mnum_steps)\n\u001b[1;32m     52\u001b[0m new_idx \u001b[38;5;241m=\u001b[39m step_idx \u001b[38;5;241m+\u001b[39m inference_horizon\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_idx \u001b[38;5;241m<\u001b[39m results\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/projects/python/thesis/Geometric-Flow-Matching/utils/schemes.py:24\u001b[0m, in \u001b[0;36mRK4\u001b[0;34m(ut, x_init, t_start, t_end, num_steps, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m     23\u001b[0m     k1 \u001b[38;5;241m=\u001b[39m ut(xt, t)\n\u001b[0;32m---> 24\u001b[0m     k2 \u001b[38;5;241m=\u001b[39m ut(xt \u001b[38;5;241m+\u001b[39m dt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m k1, t \u001b[38;5;241m+\u001b[39m dt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m     25\u001b[0m     k3 \u001b[38;5;241m=\u001b[39m ut(xt \u001b[38;5;241m+\u001b[39m dt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m k2, t \u001b[38;5;241m+\u001b[39m dt\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m     26\u001b[0m     k4 \u001b[38;5;241m=\u001b[39m ut(xt \u001b[38;5;241m+\u001b[39m dt \u001b[38;5;241m*\u001b[39m k3, t \u001b[38;5;241m+\u001b[39m dt)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/python/thesis/Geometric-Flow-Matching/models/state_mlp.py:116\u001b[0m, in \u001b[0;36mWrappedVF.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, t: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(obs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs, x\u001b[38;5;241m=\u001b[39mx, t\u001b[38;5;241m=\u001b[39mt)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/python/thesis/Geometric-Flow-Matching/models/state_mlp.py:106\u001b[0m, in \u001b[0;36mStateMLP.forward\u001b[0;34m(self, obs, x, t)\u001b[0m\n\u001b[1;32m    103\u001b[0m t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_dim)\n\u001b[1;32m    105\u001b[0m h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([obs, x], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(t, h)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhorizon_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/python/thesis/Geometric-Flow-Matching/models/state_mlp.py:62\u001b[0m, in \u001b[0;36mSequentialDiffEq.forward\u001b[0;34m(self, t, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, x):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 62\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(t, x)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/python/thesis/Geometric-Flow-Matching/models/state_mlp.py:44\u001b[0m, in \u001b[0;36mDiffEqWrapper.forward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, y):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffeq(t, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/python/thesis/Geometric-Flow-Matching/models/state_mlp.py:30\u001b[0m, in \u001b[0;36mConcatLinear_v2.forward\u001b[0;34m(self, t, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, x):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hyper_bias(t\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = run_parameters['device']\n",
    "vf.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(vf.parameters(), lr=run_parameters['lr'])\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(run_parameters['epochs']):\n",
    "  for batch in train_sin:\n",
    "    optim.zero_grad()\n",
    "\n",
    "    obs, a1 = batch\n",
    "    obs, a1 = obs.to(device), a1.to(device)\n",
    "\n",
    "    a0 = torch.randn(a1.shape[0], 1, a1.shape[2])\n",
    "    a0 = a0.repeat(1, a1.shape[1], 1).to(device)\n",
    "\n",
    "    #a0 = torch.randn_like(a1)\n",
    "    t = torch.rand(a1.shape[0]).to(device)\n",
    "\n",
    "    a_t = CondOT_flow(a0, a1, t)\n",
    "    da_t = CondOT_ut(a0, a1, t)\n",
    "\n",
    "    loss = torch.pow(vf(obs=obs, x=a_t, t=t) - da_t, 2).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i > run_parameters['ema_warmup'] and i % run_parameters['ema_update'] == 0: \n",
    "      ema_vf.update()\n",
    "\n",
    "  if i % run_parameters['print_every'] == 0:\n",
    "      elapsed = time.time() - start_time\n",
    "      print('| iter {:6d} | {:5.2f} ms/step | loss {:8.3f} '\n",
    "            .format(i, elapsed*1000/run_parameters['print_every'], loss.item()))\n",
    "      start_time = time.time()\n",
    "      with torch.no_grad():\n",
    "        ema_vf.store()\n",
    "        ema_vf.copy_to()\n",
    "        loss_val = validate(vf, val_sin)\n",
    "        ema_vf.restore()  # Restore original weights\n",
    "        print('| iter {:6d} | validation loss: {:8.3f} '.format(i, loss_val))\n",
    "  if i > 0 and i % run_parameters['save_epoch'] == 0:\n",
    "    print(\"Saving checkpoint for \" + str(i) + \"th epoch\")\n",
    "    torch.save(vf.state_dict(), \"./vf_lipman\" + str(run_parameters['scale_factor']) + \"_\" + str(i) + \".pth\")\n",
    "\n",
    "  if i % run_parameters['inf_every'] == 0:\n",
    "    with torch.no_grad():\n",
    "      ema_vf.store()\n",
    "      ema_vf.copy_to()\n",
    "      results = []\n",
    "      samples = []\n",
    "      for _ in range(run_parameters['inf_runs_num']):\n",
    "        res, samp = infer_model(model=vf,\n",
    "                                start=inf_obs,\n",
    "                                scheme=RK4,\n",
    "                                inference_horizon=run_parameters['inference_horizon'],\n",
    "                                sample_points=1000//run_parameters['downsample'])\n",
    "        results.append(res)\n",
    "        samples.append(samp)\n",
    "      error = evaluate_model(model=vf, \n",
    "                             gt_obs=gt_obs,\n",
    "                             horizon_obs=gt_horizon,\n",
    "                             scheme=RK4, \n",
    "                             num_steps=100)\n",
    "      plot_flow(results, samples, gt_obs)\n",
    "      plot_error_for_each_point(gt_obs, error)\n",
    "      ema_vf.restore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vf.state_dict(), \"./vf_euclidean\" + str(run_parameters['scale_factor']) + \"_\" + str(20000) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf.load_state_dict(torch.load(\"./vf_euclidean2.0_20000.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "samples=[]\n",
    "for _ in range(6):\n",
    "        res, samp = infer_model(model=vf,\n",
    "                                start=inf_obs,\n",
    "                                scheme=RK4,\n",
    "                                inference_horizon=run_parameters['inference_horizon'],\n",
    "                                sample_points=1000//run_parameters['downsample'])\n",
    "        results.append(res)\n",
    "        samples.append(samp)\n",
    "plot_flow(results, samples, gt_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tens = torch.stack(results, dim=0)\n",
    "samp_tens = torch.stack(samples, dim=0)\n",
    "res_tens = res_tens[1:, :, :]\n",
    "samp_tens = samp_tens[1:, :, :]\n",
    "torch.save(res_tens,\"euclidean_inference.pt\")\n",
    "torch.save(samp_tens,\"euclidean_samples.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
